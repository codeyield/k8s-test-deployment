# Пример k8s манифеста для веб-приложения

## Описание задачи

- Имеется мультизональный кластер на 3 зоны, в котором 5 нод
- Приложение требует около 5-10 секунд для инициализации
- По результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой
- На первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. По памяти всегда “ровно” в районе 128M memory
- Приложение имеет дневной цикл по нагрузке – ночью запросов на порядки меньше, пик – днём
- Необходим максимально отказоустойчивый deployment
- Необходимо минимальное потребление ресурсов

## Решение

### Манифест [deployment.yaml](deployment.yaml) с комментариями внутри.

### 1. Мультизональность

Поскольку кластер мультизональный (3 зоны), распределим поды по всем зонам (топологическим доменам) для обеспечения высокой доступности, для чего испольуем **topologySpreadConstraints**. С параметром **maxSkew: 1** при 5 подах получим распределение 2-2-1 по зонам. При скейлинге и увеличении количества реплик до 10 (например), получим распределение 4-3-3 по зонам.

### 2. Распределение по нодам

Используем **podAntiAffinity** для распределения подов по разным нодам. Установим предпочтительные (не жесткие) требования и не будем перемещать поды при изменении условий.

### 3. Количество реплик

Поскольку 4 пода справляются с пиковой нагрузкой, то для обеспечения отказоустойчивости добавим еще 1 под, итого 5 подов. Это в норме, без учета масштабирования во время повышенной дневной нагрузки (см. ниже).

### 4. Ресурсы

Начальное потребление CPU высокое, затем стабилизируется на уровне 0.1 CPU. Из условия задачи неизвестно точно, насколько "высокое" потребление CPU при иницализации. Выяснить подходящие CPU limits можно следующими способами:

- Использовать данные мониторинга и метрик для оценки потребления ресурсов подами
- Выполнить ручной подбор "сверху вниз" или "снизу вверх" - ставим высокий/низкий лимит и постепенно уменьшаем/увеливаем, пока поды не начнут/не перестанут фейлиться (для продового приложения способ не очень)
- Использовать Vertical Pod Autoscaler (deployment в режиме "Off" или "Recommend") для анализа фактического использования ресурсов подами
- Использовать Init Containers с высоким CPU limits для запуска приложения. Основной (рабочий) контейнер может иметь относительно низкий запас по CPU limits. Потребуется модификация приложения таким образом, чтобы оно поддерживало "режим иницализации" и "рабочий режим" (требует участия разработчика)
- Профилирование приложения (требует участия разработчика)
- Тестирование приложения в разных условиях нагрузки (отдельная рисерч задача)

Для памяти, поскольку ее потребление стабильное около 128M, можно предусмотреть любой разумный запас memory limits, например +50%. Предполагается, что выбираться этот лимит не будет, поэтому лишнего расхода ресурсов здесь нет.

### 5. Инициализация

Приложению требуется 5-10 секунд для инициализации, поэтому **readinessProbe** настроена с учетом этого времени. **livenessProbe** выставлена приблизительно, может потребоваться уточнение. Предполагается, что приложение имеет /healthcheck URL, доступный по указанному порту.

### 6. Циклы нагрузки и масштабирование

Учитывая дневной цикл нагрузки, используется **HorizontalPodAutoscaler** для автоматического масштабирования. Параметр **maxReplicas** требует уточнения, исходя из максимальной фактической нагрузки в дневное время - т.е. насколько именно требуется масштабировать приложение. 

Параметр **targetAverageUtilization** может потребовать уточнения, исходя из скорости роста нагрузки и наличия "всплесков" трафика/нагрузки. Т.е. насколько агрессивное масштабирование требуется. Первоначально можно выставить около 70-80%, пока нет более точных данных.

### 7. Стратегия развертывания

Используем **RollingUpdate** для плавного обновления без простоев. Используем 1 дополнительный под для раскатки обновления, и ноль недоступных подов для обеспечения отказоустойчивости.
